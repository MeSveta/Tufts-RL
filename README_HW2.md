<img width="527" alt="trace_rack" src="https://github.com/user-attachments/assets/d5259872-803f-4bf1-9e18-5f898c2dc3f7" />

1) please copy the code from https://github.com/MeSveta/Tufts-RL/tree/main/RL_a2
2) install requirments.txt by running the following command in the local terminal: "pip install -r requirements.txt"
3) You can produce your own maps by using "build_track_map.py" or use already save maps in trace_track_env/maps  
4) Run "Run_Monte_Carlo.py"  with train = True in order to train the_map.py" agent
5) Run "Run_Monte_Carlo.py"  with train = False to evaluate the rewards convergence and trajectories

